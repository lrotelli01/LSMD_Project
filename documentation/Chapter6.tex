\chapter{Most relevant queries}

This chapter presents the most relevant queries implemented in the application, showcasing how each database technology is leveraged to fulfill specific functional requirements. The queries are organized by database system and demonstrate the query-driven design approach adopted throughout the project.

\section{MongoDB Queries}

MongoDB serves as the primary database for the application, handling the majority of data storage and retrieval operations. The queries range from simple CRUD operations to complex aggregation pipelines for business analytics.

\subsection{Property Search and Filtering}

The property search functionality is one of the most critical features of the platform, allowing users to find accommodations based on multiple criteria.

\subsubsection{Advanced Search with Dynamic Criteria}

The \texttt{PropertyService} implements a dynamic query builder that constructs MongoDB queries based on user-provided filters:

\begin{minted}[fontsize=\small]{java}
public List<PropertyResponseDTO> searchProperties(String city, 
        Double minPrice, Double maxPrice, List<String> amenities) {
    Query query = new Query();

    // Case-insensitive city search using regex
    if (city != null && !city.trim().isEmpty()) {
        query.addCriteria(Criteria.where("city").regex(city, "i"));
    }

    // All specified amenities must be present
    if (amenities != null && !amenities.isEmpty()) {
        query.addCriteria(Criteria.where("amenities").all(amenities));
    }

    // Price range filter on nested room documents
    if (minPrice != null || maxPrice != null) {
        Criteria priceCriteria = Criteria.where("pricePerNightAdults");
        if (minPrice != null) priceCriteria.gte(minPrice);
        if (maxPrice != null) priceCriteria.lte(maxPrice);
        query.addCriteria(Criteria.where("rooms").elemMatch(priceCriteria));
    }

    return mongoTemplate.find(query, Property.class);
}
\end{minted}

Key aspects of this query:
\begin{itemize}
    \item \textbf{Case-insensitive regex}: The \texttt{regex(city, "i")} operator enables flexible text matching regardless of capitalization
    \item \textbf{\$all operator}: Ensures all specified amenities are present in the property, not just one of them
    \item \textbf{\$elemMatch}: Queries nested array elements (rooms) with compound conditions
\end{itemize}

\subsubsection{Geospatial Search}

For map-based property discovery, the application uses MongoDB's geospatial capabilities:

\begin{minted}[fontsize=\small]{java}
public List<PropertyResponseDTO> getPropertiesInArea(
        double lat, double lon, double radiusKm) {
    Query query = new Query();
    query.addCriteria(
        Criteria.where("location")
            .nearSphere(new Point(lon, lat))
            .maxDistance(radiusKm / 6378.1)  // Convert km to radians
    );
    return mongoTemplate.find(query, Property.class);
}
\end{minted}

The \texttt{\$nearSphere} operator uses spherical geometry for accurate distance calculations on Earth's surface, essential for travel applications.

\subsection{Reservation Availability Checking}

One of the most critical queries ensures that double-booking is prevented:

\begin{minted}[fontsize=\small]{java}
@Query("{ 'roomId': ?0, 'status': { $ne: 'cancelled' }, " +
       "'dates.checkIn': { $lt: ?2 }, 'dates.checkOut': { $gt: ?1 } }")
List<Reservation> findOverlappingReservations(
    String roomId, LocalDate newCheckIn, LocalDate newCheckOut);
\end{minted}

This query implements the classic interval overlap detection algorithm:
\begin{itemize}
    \item Two intervals [A, B] and [C, D] overlap if and only if A < D AND C < B
    \item The \texttt{\$ne: 'cancelled'} filter excludes cancelled reservations from availability checks
    \item Proper indexing on \texttt{roomId} and \texttt{dates.checkIn} ensures efficient execution
\end{itemize}

\subsection{Message Conversation Retrieval}

The messaging system requires bidirectional message retrieval:

\begin{minted}[fontsize=\small]{java}
@Query(value = "{$or: [ " +
    "{ 'senderId': ?0, 'recipientId': ?1 }, " +
    "{ 'senderId': ?1, 'recipientId': ?0 } ]}", 
    sort = "{ 'timestamp' : 1 }")
List<Message> findConversation(String user1, String user2);
\end{minted}

This query:
\begin{itemize}
    \item Uses \texttt{\$or} to match messages in both directions
    \item Sorts by timestamp ascending to display conversation chronologically
    \item Leverages compound index on (senderId, recipientId) for performance
\end{itemize}

\subsection{Review Analytics with Date Filtering}

For the manager analytics dashboard, reviews can be filtered by creation date:

\begin{minted}[fontsize=\small]{java}
@Query("{ 'propertyId': ?0, 'creationDate': { $gte: ?1, $lte: ?2 } }")
List<Review> findByPropertyIdAndCreationDateBetween(
    String propertyId, LocalDate startDate, LocalDate endDate);
\end{minted}

The \texttt{\$gte} (greater than or equal) and \texttt{\$lte} (less than or equal) operators create an inclusive date range filter.

\subsection{Active Bookings Detection}

To prevent account deletion while active bookings exist:

\begin{minted}[fontsize=\small]{java}
@Query(value = "{ 'userId': ?0, 'status': 'confirmed', " +
    "'dates.checkOut': { $gt: ?1 } }", exists = true)
boolean hasActiveBookings(String userId, LocalDate today);
\end{minted}

The \texttt{exists = true} parameter makes this an existence check query, returning a boolean instead of retrieving documents, which is more efficient for validation purposes.

\subsection{MongoDB Aggregation Pipeline}

For complex analytics calculations, the application leverages MongoDB's Aggregation Framework, which provides better performance than client-side processing for large datasets.

\subsubsection{Reservation Statistics Aggregation}

\begin{minted}[fontsize=\small]{java}
private AnalyticsResponseDTO calculateAggregatedAnalyticsWithPipeline(
        List<Property> properties, LocalDate startDate, LocalDate endDate) {
    
    List<String> allRoomIds = properties.stream()
        .flatMap(p -> p.getRooms().stream())
        .map(Room::getId)
        .collect(Collectors.toList());

    // Build match criteria
    Criteria criteria = Criteria.where("roomId").in(allRoomIds);
    if (startDate != null && endDate != null) {
        criteria = criteria.and("dates.checkIn").gte(startDate).lte(endDate);
    }

    // Pipeline stages
    MatchOperation matchStage = Aggregation.match(criteria);

    GroupOperation groupStage = Aggregation.group()
        .count().as("totalReservations")
        .sum(ConditionalOperators
            .when(Criteria.where("status").is("CONFIRMED"))
            .then(1).otherwise(0))
            .as("confirmed")
        .sum(ConditionalOperators
            .when(Criteria.where("status").is("CANCELLED"))
            .then(1).otherwise(0))
            .as("cancelled")
        .sum(ConditionalOperators
            .when(Criteria.where("status").is("COMPLETED"))
            .then(1).otherwise(0))
            .as("completed")
        .sum("adults").as("totalAdults")
        .sum("children").as("totalChildren");

    Aggregation aggregation = Aggregation.newAggregation(
        matchStage, groupStage);
    
    AggregationResults<AggregatedResult> results = mongoTemplate
        .aggregate(aggregation, "reservations", AggregatedResult.class);

    return results.getUniqueMappedResult();
}
\end{minted}

This aggregation pipeline demonstrates:
\begin{itemize}
    \item \textbf{\$match stage}: Filters documents early to reduce processing
    \item \textbf{\$group stage}: Aggregates statistics across all matching documents
    \item \textbf{Conditional operators}: Counts reservations by status using \texttt{\$cond} expressions
    \item \textbf{Type-safe results}: Maps aggregation output to a strongly-typed DTO
\end{itemize}

\section{Neo4j Queries}

Neo4j powers the recommendation engine through graph-based queries using Cypher, Neo4j's declarative query language.

\subsection{Collaborative Filtering Recommendations}

The primary recommendation algorithm identifies properties booked by users with similar preferences:

\begin{minted}[fontsize=\small]{java}
public List<PropertyResponseDTO> getCollaborativeRecommendations(
        String propertyId) {
    
    String cypherQuery = """
        MATCH (p:Property {propertyId: $propId})<-[:BOOKED]-(u:User)
              -[:BOOKED]->(other:Property)
        RETURN other.propertyId AS recommendedId, 
               count(*) AS strength
        ORDER BY strength DESC
        LIMIT 5
    """;

    Collection<String> recommendedIds = neo4jClient.query(cypherQuery)
        .bind(propertyId).to("propId")
        .fetchAs(String.class)
        .mappedBy((typeSystem, record) -> 
            record.get("recommendedId").asString())
        .all();

    return propertyRepository.findAllById(recommendedIds);
}
\end{minted}

The Cypher query pattern works as follows:
\begin{itemize}
    \item \textbf{Start node}: Finds the property being viewed
    \item \textbf{First hop}: Traverses \texttt{BOOKED} relationships backward to find users who booked this property
    \item \textbf{Second hop}: Traverses \texttt{BOOKED} relationships forward to find other properties these users booked
    \item \textbf{Aggregation}: Groups by property and counts co-occurrences as "strength"
    \item \textbf{Ranking}: Orders by strength to surface the most relevant recommendations
\end{itemize}

This implements the classic "users who booked X also booked Y" collaborative filtering pattern.

\subsection{Graph Constraints for Data Integrity}

The application creates constraints at startup to ensure graph integrity:

\begin{minted}[fontsize=\small]{java}
@EventListener(ApplicationReadyEvent.class)
public void createIndexesAndConstraints() {
    List<String> startupQueries = List.of(
        // Property uniqueness - O(1) lookup for recommendations
        "CREATE CONSTRAINT property_id_unique IF NOT EXISTS " +
        "FOR (p:Property) REQUIRE p.id IS UNIQUE",

        // User uniqueness - essential for collaborative filtering
        "CREATE CONSTRAINT user_id_unique IF NOT EXISTS " +
        "FOR (u:User) REQUIRE u.id IS UNIQUE",

        // Amenity uniqueness - ensures shared nodes for traversal
        "CREATE CONSTRAINT amenity_name_unique IF NOT EXISTS " +
        "FOR (a:Amenity) REQUIRE a.name IS UNIQUE"
    );

    startupQueries.forEach(query -> neo4jClient.query(query).run());
}
\end{minted}

These constraints serve dual purposes:
\begin{itemize}
    \item \textbf{Data integrity}: Prevents duplicate nodes
    \item \textbf{Performance}: Creates implicit indexes for O(1) lookups
\end{itemize}

\section{Redis Queries and Operations}

Redis provides in-memory data structures for caching, session management, and real-time features.

\subsection{Token Blacklisting for Secure Logout}

JWT tokens are stateless by design, but the application implements secure logout through Redis blacklisting:

\begin{minted}[fontsize=\small]{java}
public void blacklistToken(String token) {
    String cleanedToken = cleanToken(token);
    Claims claims = getClaims(cleanedToken);
    
    // Calculate remaining TTL
    long tokenExpiration = claims.getExpiration().getTime();
    long currentTime = System.currentTimeMillis();
    long ttl = tokenExpiration - currentTime;

    if (ttl > 0) {
        // Key format: "blacklist:<token>"
        redisTemplate.opsForValue()
            .set("blacklist:" + cleanedToken, "true", 
                 ttl, TimeUnit.MILLISECONDS);
    }
}

private boolean isTokenBlacklisted(String token) {
    Boolean exists = redisTemplate.hasKey("blacklist:" + token);
    return exists != null && exists;
}
\end{minted}

Key design decisions:
\begin{itemize}
    \item \textbf{TTL-based expiration}: Blacklist entries automatically expire when the token would have naturally expired, preventing unbounded memory growth
    \item \textbf{String data type}: Simple key-value structure for O(1) lookup
    \item \textbf{Validation integration}: Token validation checks blacklist before accepting requests
\end{itemize}

\subsection{Pessimistic Locking for Reservations}

To prevent double-booking during the payment window, Redis implements temporary locks:

\begin{minted}[fontsize=\small]{java}
private static final String REDIS_PREFIX = "temp_res:";

public ReservationResponseDTO initiateReservation(
        String token, ReservationRequestDTO request) {
    
    // Check MongoDB for confirmed bookings
    List<Reservation> confirmedOverlaps = reservationRepository
        .findOverlappingReservations(room.getId(), 
            request.getCheckIn(), request.getCheckOut());
    
    if (!confirmedOverlaps.isEmpty()) {
        throw new IllegalStateException("Room already booked");
    }

    // Check Redis for temporary locks
    Set<String> keys = redisTemplate.keys(REDIS_PREFIX + "*");
    if (keys != null) {
        for (String key : keys) {
            Reservation pending = objectMapper.convertValue(
                redisTemplate.opsForValue().get(key), 
                Reservation.class);
            
            if (pending != null && 
                pending.getRoomId().equals(room.getId()) &&
                isOverlapping(pending.getDates(), 
                    request.getCheckIn(), request.getCheckOut())) {
                throw new IllegalStateException(
                    "Room being paid for. Try again in 15 mins.");
            }
        }
    }

    // Create temporary reservation with 15-minute TTL
    String tempId = UUID.randomUUID().toString();
    Reservation tempReservation = Reservation.builder()
        .id(tempId)
        .roomId(room.getId())
        .dates(new ReservationDates(
            request.getCheckIn(), request.getCheckOut()))
        .status("PENDING_PAYMENT")
        .build();

    redisTemplate.opsForValue()
        .set(REDIS_PREFIX + tempId, tempReservation, 
             15, TimeUnit.MINUTES);
    
    return mapToDTO(tempReservation);
}
\end{minted}

This implements a pessimistic locking pattern:
\begin{itemize}
    \item \textbf{Temporary reservation}: Stored in Redis with 15-minute TTL during payment
    \item \textbf{Overlap checking}: Both MongoDB (confirmed) and Redis (pending) are checked
    \item \textbf{Automatic unlock}: TTL ensures locks are released if payment is abandoned
\end{itemize}

\subsection{Trending Properties with Sorted Sets}

Redis sorted sets maintain real-time property popularity rankings:

\begin{minted}[fontsize=\small]{java}
// Increment view count when property is viewed
public PropertyResponseDTO getPropertyDetails(String propertyId) {
    Property property = propertyRepository.findById(propertyId)
        .orElseThrow(() -> new IllegalArgumentException("Not found"));

    // ZINCRBY trending_properties 1 <propertyId>
    redisTemplate.opsForZSet()
        .incrementScore("trending_properties", propertyId, 1);

    return mapToDTO(property);
}

// Get top 10 trending properties
public List<PropertyResponseDTO> getTrendingProperties() {
    // ZREVRANGE trending_properties 0 9
    var topIds = redisTemplate.opsForZSet()
        .reverseRange("trending_properties", 0, 9);
    
    if (topIds == null || topIds.isEmpty()) return List.of();

    List<String> ids = topIds.stream()
        .map(Object::toString)
        .collect(Collectors.toList());
    
    return propertyRepository.findAllById(ids).stream()
        .map(this::mapToDTO)
        .collect(Collectors.toList());
}
\end{minted}

Redis sorted sets provide:
\begin{itemize}
    \item \textbf{O(log N) insertion}: Efficient score updates
    \item \textbf{O(log N + M) range queries}: Fast top-K retrieval
    \item \textbf{Atomic operations}: Thread-safe score increments
\end{itemize}

\subsection{User Browsing History with Lists}

Redis lists store recently viewed properties per user:

\begin{minted}[fontsize=\small]{java}
public void addToUserHistory(String userId, String propertyId) {
    String key = "history:" + userId;
    
    // LPUSH adds to front of list
    redisTemplate.opsForList().leftPush(key, propertyId);
    
    // LTRIM keeps only last 10 items
    redisTemplate.opsForList().trim(key, 0, 9);
}

public List<PropertyResponseDTO> getUserHistory(String userId) {
    String key = "history:" + userId;
    
    // LRANGE retrieves all items
    List<Object> historyIds = redisTemplate.opsForList()
        .range(key, 0, -1);
    
    if (historyIds == null || historyIds.isEmpty()) 
        return List.of();

    List<String> ids = historyIds.stream()
        .map(Object::toString)
        .collect(Collectors.toList());
    
    return propertyRepository.findAllById(ids).stream()
        .map(this::mapToDTO)
        .collect(Collectors.toList());
}
\end{minted}

This pattern:
\begin{itemize}
    \item Uses \texttt{LPUSH} for O(1) insertion at head
    \item Uses \texttt{LTRIM} to maintain fixed-size history (last 10 properties)
    \item Provides O(1) retrieval for "recently viewed" feature
\end{itemize}

\section{Content-Based Filtering with MongoDB}

The application also implements content-based recommendations using MongoDB:

\begin{minted}[fontsize=\small]{java}
public List<PropertyResponseDTO> getContentBasedRecommendations(
        String propertyId) {
    Property current = propertyRepository.findById(propertyId)
        .orElse(null);
    
    if (current == null || current.getAmenities() == null || 
        current.getAmenities().isEmpty()) {
        return Collections.emptyList();
    }

    Query query = new Query();
    // Exclude current property
    query.addCriteria(Criteria.where("_id").ne(propertyId));
    // Match any shared amenities
    query.addCriteria(Criteria.where("amenities")
        .in(current.getAmenities()));
    query.limit(10);

    List<Property> candidates = mongoTemplate.find(query, Property.class);

    // Sort by number of common amenities
    candidates.sort((p1, p2) -> {
        long common1 = countCommon(p1.getAmenities(), 
            current.getAmenities());
        long common2 = countCommon(p2.getAmenities(), 
            current.getAmenities());
        return Long.compare(common2, common1);
    });

    return candidates.stream()
        .limit(5)
        .map(this::mapToDTO)
        .collect(Collectors.toList());
}

private long countCommon(List<String> l1, List<String> l2) {
    if (l1 == null || l2 == null) return 0;
    List<String> copy = new ArrayList<>(l1);
    copy.retainAll(l2);
    return copy.size();
}
\end{minted}

This query demonstrates:
\begin{itemize}
    \item \textbf{\$in operator}: Matches properties with at least one shared amenity
    \item \textbf{Client-side ranking}: Sorts by Jaccard-like similarity metric
    \item \textbf{Hybrid approach}: Database filtering + application sorting for flexibility
\end{itemize}

\section{Summary}

The query implementations in this chapter demonstrate how the application leverages each database technology's strengths:

\begin{itemize}
    \item \textbf{MongoDB}: Complex document queries, aggregation pipelines for analytics, geospatial search, and flexible schema support
    \item \textbf{Neo4j}: Graph traversal for collaborative filtering recommendations, relationship-based queries
    \item \textbf{Redis}: In-memory caching, session management, pessimistic locking, and real-time rankings
\end{itemize}

The query-driven design approach ensures that data models are optimized for the access patterns they need to support, resulting in efficient and maintainable database operations throughout the application.
